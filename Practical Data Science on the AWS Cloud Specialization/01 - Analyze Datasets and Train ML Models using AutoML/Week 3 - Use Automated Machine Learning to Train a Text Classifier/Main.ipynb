{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Use Automated Machine Learning to Train a Text Classifier**"]},{"cell_type":"markdown","metadata":{},"source":["## **Automated Machine Learning**"]},{"cell_type":"markdown","metadata":{},"source":["### **AutoML Workflow**"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-02-17.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-05-53.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-08-49.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-10-55.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-11-35.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-11-54.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-20-56.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-22-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-23-34.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-25-36.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-27-26.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-27-58.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-30-14.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-32-33.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-33-25.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-35-05.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-50-15.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-53-04.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-54-17.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-55-03.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-21-55-40.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Running experiments with Amazon SageMaker Autopilot**"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-03-28.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-04-44.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-06-48.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-09-15.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-11-46.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-12-40.png)"]},{"cell_type":"markdown","metadata":{},"source":["MultiColumnTfidfVectorizer converts collections of raw documents to a matrix of Term Frequency Inverse Document Frequency, or Tfidf features. At a high level with Tfidf, you're evaluating how relevant a word is to a document, or a collection of documents. This is done by calculating how often the words appear and the inverse document frequency of those words across a set of documents. With the MultiColumn TfidfVectorizer, it converts collections of raw documents to a matrix of Tfidf features. Let's dive a little bit deeper here, so that you understand what's happening in the background. For processing texts with machine learning tools, you need to transform the document into a vector of features. A typical approach is to put all text in a bag and then sample from it without replacement. This way you can tally how many times a given word appears and produce a vector of counts. This approach is called Bag-of-Words. Once you produce a vector using bag-of-words, you want to quantify how important word is to a document, relative to others in the corpus. What you're aiming for here is a concise and reliable statistical description of a word's weight. This weight has to increase proportionately to the number of times that it happens in a given text, but it should decrease if the word is very frequent in that corpus because it will lack specificity. The Tfidf is a concise measure that will achieve exactly that. So, let's do a divide and conquer approach and start with the formula for term frequency, or TF: T refers to a term or a word, lowercase d to a document, and uppercase D to the corpus. The TF is the relative frequency of a word in a document, against all other words in that document. So because every document is different in length, it is possible that a term would appear many more times in long documents than in shorter ones. More concisely, it's the ratio of the word frequency in a document, over the same of the frequencies of all words in that specific document. Inverse document frequency, or IDF, measures how important a term is by looking at the whole corpus. "]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-16-27.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-17-12.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-17-44.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-19-38.png)"]},{"cell_type":"markdown","metadata":{},"source":["The denominator tallies up all the instances of a term in the corpus. So as you will see, very common words like is, if, or the, may appear many times, but they have very little importance. Thus, you need to scale down the weight of frequent terms, while you scale up the weight of rare ones. This is the whole point of IDF, which puts this quotient on a log scale. The only caveat with this formulation is that it might lead to division by zero. Let's do an example. In a document containing 200 words, where the word food appears ten times, the term frequency, or the TF, for food is then 10 divided by 200, which equals 0.05. If the corpus has 1 million documents and the word food appears in 1000 of these documents, the inverse document frequency, or IDF, is log 1 million divided by 1000, or 3. The Tfidf weight is the product of these quantities, 0.05 times 3, which equals 0.15. In this section, I covered how you can configure and launch your Autopilot job, using your input dataset and defining your target labels. I also covered the approach that Autopilot takes for text transformations, including some of the theory behind those transformations. In the next section, I'll cover the resources and artifacts generated by Autopilot once your job is complete. "]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-21-58.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-23-24.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-24-00.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Demo**"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-52-10.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-53-46.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-54-34.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-54-59.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-55-19.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-55-37.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-56-37.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-57-33.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-57-53.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-58-38.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-59-17.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-22-59-58.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-00-35.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-01-03.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-08-49.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-09-59.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-11-06.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-11-56.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-13-00.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-13-59.png)"]},{"cell_type":"markdown","metadata":{},"source":["I'm going to click on the first day to pre processor here called dpp0. In this view, you can see the Python code that was generated for your first candidate model which uses a Sagemaker SciKit Learn extension. In this case you can see autopilot is using the multicolumntfidfvectorizer that I talked about before and has automatically identified a few configuration parameters. Some of those configuration parameters include the max_df, which defines the proportion of terms to ignore, which is basically identifying the stop words that are specific to your text data. So, these are words that appear to frequently, which could be words like 'is' or 'the' or for this specific use case, you may see the word 'product' a lot as well. In this case, it means ignore terms that appear in more than 99.41 of the reviews. "]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-29-25.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-30-03.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-30-35.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-31-10.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-31-31.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-32-06.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-32-23.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-33-10.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-34-24.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-34-43.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-35-39.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-36-18.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-29-23-37-32.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Model hosting**"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-30-00-25-41.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-30-00-26-47.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-30-00-27-24.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-30-00-28-20.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2023-12-30-00-28-34.png)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNAnc3IBjNxONndNFHGocAe","collapsed_sections":[],"name":"M1Assignment1 Solution.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.6"}},"nbformat":4,"nbformat_minor":0}
