{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **Applied Python for MLOps**"]},{"cell_type":"markdown","metadata":{},"source":["## **Working with APIs and SDKs**"]},{"cell_type":"markdown","metadata":{},"source":["Azure CLI (Azure Command-Line Interface): A command-line tool that allows management and interaction with Azure services and resources."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import azure.cli.core\n","\n","cli = azure.cli.core.AzureCli()\n","cli.invoke([\"storage\", \"account\", \"list\"])"]},{"cell_type":"markdown","metadata":{},"source":["Azure ML (Azure Machine Learning) Studio: A cloud-based environment for machine learning development and deployment."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from azureml.core import Workspace\n","\n","ws = Workspace.create(name='myworkspace', \n","                     subscription_id='...', \n","                     resource_group='myresourcegroup', \n","                     location='eastus')"]},{"cell_type":"markdown","metadata":{},"source":["Transformers: A Hugging Face library for natural language processing tasks."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import pipeline\n","\n","classifier = pipeline(\"sentiment-analysis\")\n","result = classifier(\"I love this course!\")\n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["Datasets: A Hugging Face library for loading datasets."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from datasets import load_dataset\n","\n","dataset = load_dataset(\"glue\", \"mrpc\")\n","train_dataset = dataset[\"train\"]\n","print(len(train_dataset))"]},{"cell_type":"markdown","metadata":{},"source":["Open Datasets: An Azure resource for loading curated public datasets."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from azureml.opendatasets import PublicHolidays\n","\n","holidays = PublicHolidays()\n","holidays_df = holidays.to_pandas_dataframe()\n","print(holidays_df.head())"]},{"cell_type":"markdown","metadata":{},"source":["### **Installing Azure ML CLI**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-05-23-28-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["**Install Azure on Mac:**\n","\n","brew update && brew install azure-cli"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-05-23-50-00.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-05-23-50-34.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-05-23-54-36.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-00-11-30.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Azure ML Studio with Python**"]},{"cell_type":"markdown","metadata":{},"source":["**Initial Step:**\n","\n","In the Azure portal, find your subscription ID and tenant ID. Inside Azure Machine Learning, create a workspace with a resource group. Navigate to the workspace and open Azure Studio. Create a compute node and open a new jupyter notebook, and change the kernel to SDK v2. In your local VS code, install the Azure Machine Learning extension and change your kernel to the Azure ML compute node with SDK v2."]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-20-01.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-22-42.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-23-35.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-28-28.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-31-38.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-32-08.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-33-19.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-39-33.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-44-46.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-46-50.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-47-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-49-53.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-54-26.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-55-01.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-56-17.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-56-38.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-56-56.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-57-42.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-07-57-53.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Hugging ace Transformers**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-21-13-08.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-21-13-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-21-15-30.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-21-16-11.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-21-17-09.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-21-17-44.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-21-19-27.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Hugging Face Datasets**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-07-01.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-09-22.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-10-47.png)"]},{"cell_type":"markdown","metadata":{},"source":["**Note:** Slash means some user uploaded a dataset."]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-12-22.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-13-51.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-14-45.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Azure Open Datasets**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-17-05.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-22-28.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-23-29.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-48-53.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-49-37.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-22-50-23.png)"]},{"cell_type":"markdown","metadata":{},"source":["## **Automation with Command-Line Tools**"]},{"cell_type":"markdown","metadata":{},"source":["### **Creating a Single File Script**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-05-48-22.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-05-50-38.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-05-52-12.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-05-52-56.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-05-54-54.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Using the ArgParse Framework**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-06-42-05.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-06-42-36.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-06-44-13.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-06-48-09.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-06-50-47.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Declaring Dependencies**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-06-55-12.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-06-56-51.png)"]},{"cell_type":"markdown","metadata":{},"source":["The difference between a pinned version in the requirements.txt and pip install is:"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-08-20.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Using the Click Framework**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-13-18.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-22-33.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-31-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-32-29.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-33-02.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-52-10.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-07-54-03.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Packaging your Project**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-00-31.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-01-50.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-04-15.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-04-48.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Solving a Machine Learning Problem with a CLI Tool**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-07-53.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-09-01.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-09-32.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-11-22.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-15-27.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-16-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-17-14.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-17-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-18-30.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-19-20.png)"]},{"cell_type":"markdown","metadata":{},"source":["and the summary is ..."]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-20-07.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-20-33.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-20-55.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-08-21-16.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Key Terms**"]},{"cell_type":"markdown","metadata":{},"source":["Click: A Python package for building command line interfaces."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import click\n","\n","@click.command()\n","@click.option('--count', default=1)\n","def hello(count):\n","    for x in range(count):\n","        click.echo('Hello World!')\n","\n","if __name__ == '__main__':\n","    hello()"]},{"cell_type":"markdown","metadata":{},"source":["ArgParse: A Python module for parsing command-line arguments."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import argparse\n","\n","parser = argparse.ArgumentParser()\n","parser.add_argument('--verbosity', action='store_true')\n","args = parser.parse_args()\n","\n","if args.verbosity:\n","    print(\"Verbose mode enabled\")"]},{"cell_type":"markdown","metadata":{},"source":["sys.argv: A Python module containing command line arguments."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import sys \n","\n","print(f\"Script name: {sys.argv[0]}\")\n","print(f\"First argument: {sys.argv[1]}\") \n","print(f\"Second argument: {sys.argv[2]}\")"]},{"cell_type":"markdown","metadata":{},"source":["Setuptools: A package for building and distributing Python projects."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from setuptools import setup\n","\n","setup(\n","    name='mypackage',\n","    version='1.0',\n","    install_requires=['requests', 'click']\n",")"]},{"cell_type":"markdown","metadata":{},"source":["Entry points: Definitions linking scripts to functions in Setuptools."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from setuptools import setup\n","\n","setup(\n","  #...,\n","  entry_points = {\n","    'console_scripts': [\n","      'myscript = mypackage.mymodule:main_func',\n","    ]  \n","  }\n",")"]},{"cell_type":"markdown","metadata":{},"source":["## **Building Machine Learning APIs**"]},{"cell_type":"markdown","metadata":{},"source":["### **Introduction to Flask Framework**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-05-04.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-06-56.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-08-30.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-08-56.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-09-46.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-10-08.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Building an API with Flask**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-11-33.png)"]},{"cell_type":"markdown","metadata":{},"source":["Now let's go ahead and create an API using Flask. We already saw a little bit on how that works with the previous video where we went through some of the application, things that Flask provides you, but here with the app.py, we are going to do a few different things. We're going to use the ONNX runtime. I really liked ONNX and this is something that we will cover later in this course. But ONNX is effectively a runtime that allows you to deal with models that can be coming from other places or do other types of frameworks. As you already know, we're going to start instantiating these on Flask line number 8. This is very useful right here. That's how we get started with our application. Next, we're going to do some required things that ONNX is requiring to interact with the model. We're going to create a session and all of this happens right here at the very beginning because that's needed as soon as the application is running. Then we're going to have a helper. This is called a two NumPy helper function here that is going to verify if I have a CPU, or otherwise if I don't have one, it's going to just figure out what is it that we need. We're going to keep our very basic HTML there with RoBERTa sentiment analysis. We're going to do some sentiment analysis with the RoBERTa sequence classification model. Next, we're going to expose route here that is going to be slash predict that's happening right there on the route. Only the post method is going to be available. We're going to use this predict function right there. Now, next on line 26 through lines 32, 33, we're going to do some of the heavy lifting there of the processing on how to send that data to the model. This is not a very good API right now because he doesn't document correctly where the request is coming from. This is implicitly using a request. If you want to interact with Flask data that is coming in, you would import that. You can see request is coming here, but it's not being passed onto the function itself. What happens here is that you need to use request.json. "]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-14-27.png)"]},{"cell_type":"markdown","metadata":{},"source":["The JSON portion of it is already serialized. Here these brackets and the zero index means that is the first item. We're assuming that we're going to get a list and we're going to grab just the first one. Next, we're going to make sure that we're going to process that and we're going to see if the sentiment is positive or negative and we're going to return JSON file, which is a helper from Flask, which is going to allow us to return JSON. If I scroll all the way down here, you can see here that I'm going to use port 5,000 and bind to any host. I'm going to set debug to true. Now that I have those out of the way, there's a couple of things that you need to know for this one to work. Now, you can see here that I'm using RoBERTa sequence classification. So it requires me to have the model and that's why I have the model right here. I have my pre-downloaded that model. It's available on the file system. So that's already there. It's almost a 500 megabyte binary file. That's something to keep in mind. Now I'm going to open up the terminal and we're going to see how to drag with these. The first thing that we do is I'm already activated on the virtual environment. I'm in the right directory where the ONNX model and the app.py is. I'm going to choose run Python app.pay, and that should bring up the Flask application that we just went through. Development server, let's just actually try it out. Let's open that. That's fine. That's RoBERTa sentiment analysis. If I go back to the theater, you can see that is coming from this home function and this is the HTML that is being returned. That's fine. But what we want to is actually interact with the predict function here. You can see it's only accepting post and it says slash predict. We need to put some JSON there. Now, the tricky part is that we need to drag with that. We either need an extension on the nature, like we can install an extension right here, or we can do it on the command line. Let's try it on the command line. That would be with curl. This is how the whole message would look like. Curl-x post means that I'm going to send a post request. I'm going to see that the Content-Type is application/json. Those are the headers. So that the framework understands how the data is going to come in. Then dash dash data means I'm going to be sending a body. The body of the request is going to be JSON. You can see here is single quotes then a list or an array using double quotes inside. That's the phrase that is going to be processed to analyze the sentiment, is going to do the sentiment analysis. The URL in this case is local host because remember it's binding to anything port 5,000/predict. Let's see what happens. Positive is false. It's now positive. Let's try to change that. We can say Flask is a very useful framework. I'm going to run that and positive it's true. That's very good. Now we can see we're interacting with the API. I'm going to close this and go back to the API and do a quick recap of what we've built. We started with installing Flask for sure in all the dependencies are in the requirements.text file. But we also are using jsonify and request to try to deal with the incoming request, as well with the response that we're going to predict after the prediction happens. The jsonify specifically happens right here in the response of the prediction. Finally, we were able to run that as always, the Flask with these little nifty app.run that allows to pass certain parameters there. We interacted with it using curl on the command-line tool. But effectively you could use any other type of client, like say like Python to properly interact with API that is exposed. That's it. That is how you build and interact and work with a Flask API."]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-14-40.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-15-06.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-15-55.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-16-52.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Introduction to the FastAPI Framework**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-18-21.png)"]},{"cell_type":"markdown","metadata":{},"source":["Let's do an introduction to the FastAPI framework. Now, the FastAPI framework is very similar to the Flask framework as well. But here you'll start seeing some of the slight differences in where that it makes sense to use one or the other. I personally really like FastAPI, and we'll take a look at how that looks in this quick lesson. Let's start with this repository that already tells us that to run this application, we will need to use a couple of different things. I'm just going to start by telling us that we need Uvicorn. It's an executable. Behind the scenes, all that it is, it's a Python web framework that allows us to run a Python application and it needs a couple of things first the host, and then it needs to know what is the Python module in this case, I'll have a main.py and then we'll have an app function that we can use. Let's take a quick look at that file so we can have these main.py so let's open that, and then close the ReadMe. Here we have several different files and we don't need this one right there so when I remove that. A couple of different things you can see right here we're instantiating these FastAPI very similar to what Flask was doing before, so we'll clean that app. There's some other extra things like this app type mount that's not important right now. Basically for introduction, app equals FastAPI, we're calling that and we're instantiating these. Then we are going to expose these root just like before with Flask. In this case, app.get is how we're going to expose this root function, just for the root of like the slash, the top of the website just using the get method. That's an important distinction before you would use to have some more parameters that would indicate that, and then we're going to expose these generates slash generate only for a post request, that's how you get exposed to these generate function right here. That is fine but there are a couple of other things that are interesting here, mainly these body that is defined here on Line 18, and it has an inheritance of these base model. What is going on here? Well, you're creating like an expectation that you're going to require something that is a field in adjacent body called STRF time and that's going to be of type string that's what STRF means there. When that request comes in to the generate function, or you can see here the body is an argument that is required is going to be of type of the body object right here on Line 18. We're seeing a very basic API that allows to have all of these things ready for you. The find, the functions, the exposure, how to start seeing that. Now our key difference here is that we're using a FileResponse, this has an index.html file. If we go ahead and look at static, you will see that there's an index.html right there that shows you that you can actually use these to serve some content out. Now how to run it? Well, it's always useful to poke around the Docker file. Let's see how that works so it will use uvicorn. It will be the zero that's here, the zeros well, that binds to anything and then main that app. Let's quickly create a terminal and see how that looks and then run it and with that being running, we'll complete the introduction to FastAPI. The way we're going to do this, is Uvicorn when I follow the pattern there on the Docker file instructions so when I do dash, dash host, and when to do the four zeros right here, and they want to say main app. Again, main app means that it's the main.py module and then AP is going to be Line 14, the FastAPI. That's what's going to be running, I'm going run that. There you go. The started server process waiting for application startup now VSCode is telling me that 40,000 is available, I'm going to open it in the browser and the first thing is going to connect a DCC HTML, is a containerized Python API. But we want to interact with these APIs so one of the good things about FastAPI is that you can interact with dynamically generated help and that is always at slash docs, as you can see here, the very top that is not exposed so if you look at the main.py, I don't have a slash docs are exposed anywhere. However, the API does allow me to expose it and interact with it so you can see it right here and you have to slash generate it understand that there's a boast. I'm going to click here, I'm going to say I want to try it out. STRF time is there, it's actually grabbing all of the documentation from my function and putting it there, generate the current time giving an STRF time template and for example percentage Y, percentage M percentage D. I'm going to try that, I'm going to put it right here, I'm going to see what these does. I'm going to say percent Y and I'm going to execute and we're going to see what happens. Let's scroll here to the responses and see what happens. The response completed and you can see that the response body is 2022, that's because percent Y, it's how Python translates to the full year, so that's the response body. But not only that, we also have the full curl command D if we wanted to try that somewhere else. That's perfect. Also the request URL. Critical pieces of information curl the actual URL, the response and the response headers so very useful preloaded all with the open API spec that allows you to interact dynamically with the running API. There you go that's an introduction to FastAPI. That's how you can run it. That's how you can define some of the functions that are going to be dealing with input and output and we'll see next how we can entrap further by introducing machinery models. happens. Let's scroll here to the responses and see what happens. The response completed and you can see that the response body is 2022, that's because percent Y, it's how Python translates to the full year, so that's the response body. But not only that, we also have the full curl command D if we wanted to try that somewhere else. That's perfect. Also the request URL. Critical pieces of information curl the actual URL, the response and the response headers so very useful preloaded all with the open API spec that allows you to interact dynamically with the running API. There you go that's an introduction to FastAPI. That's how you can run it. That's how you can define some of the functions that are going to be dealing with input and output and we'll see next how we can entrap further by introducing machinery models. : Added to Selection. Press [⌘ + S] to save as a note Required ​ "]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-21-10.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-20-22.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Building an API with FastAPI**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-21-59.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-22-21.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-23-57.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-24-18.png)"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-24-46.png)"]},{"cell_type":"markdown","metadata":{},"source":["### **Python API Best Practices**"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-25-55.png)"]},{"cell_type":"markdown","metadata":{},"source":["Now let's go on to some of the API best practices, especially when you're building these APIs, it is essential to follow certain good best practices, especially I want to concentrate on HTTP error codes. HTTP error codes or its usage is critical because it allows you to define specific errors that are tied to certain behaviors. For example, the 401 is useful when access to resource is unauthorized. You want to use a 401 when you shouldn't be, or the user or the client shouldn't be accessing something that requires authorization and the client is not authorized. A few of the ones that are common are the 400 Bad Request. That is usually when a schema fails. Let's say, for example, if you're passing in the string and it's requiring an integer, then most commonly you will be using a Bad Request right here. Unauthorized we already saw, which is that 401 and 404 Not Found. Now, a good thing to note about 404 is that sometimes a 404 is used when you don't want to let the client know if a resource exists. Say, for example, if it's poking around to check inventory or say, for example, a user or a resource that requires authentication. Instead of saying 404 Not Found, they would tell some clients, hey, this resource actually doesn't exist. Say, a bad user is trying to find and phish for existing usernames then a 404 would be a way of preventing that happening unless it's authenticated. That's a good practice for a 404 that, well, is related to the unauthorized one, but might not be entirely clear.​ "]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-28-43.png)"]},{"cell_type":"markdown","metadata":{},"source":["Now, we already saw different types of requests. Specifically, we saw GET and POST, but we didn't see PUT and HEAD. Generally speaking, when you are having a GET request like this one, those are read-only requests. The client is requesting something like data or resources specifically for an API, and that's read-only. That means that the server is not writing, is not creating a new resource, it is producing the output from something that already exists. This is useful because if you're dealing with databases, you can map GET requests to a read-only database, for example. That's why that's useful. A POST request would be for writes, for creating a resource, for creating data. Say, for example, you want to submit data like a new user, for example, or you want to create a new user or create a new address. Well, that will happen with a POST. Now, if the resource already exists, but you want to add data like this one, then it is good practice to use a PUT because then you will be updating the contents of that resource that already exist. Say, for example, a user already exists, but he change addresses, that this person moved and the address has changed, well, then that would definitely be a PUT right here. Finally, a HEAD, like this one right here, would happen if you want to implement a nice feature for a client that wants to know if a resource exists. I actually have a real-world example here I'm going to use. Now, the framework here is very different from anything that we've already covered, but it should give you a good idea. Right here we have a HEAD definition right there. This is a function or actually a method that does a couple of things. But the details, again, it doesn't matter. It's just that the method is HEAD. It's saying, hey, if a request comes here, then this method will work. It's actually looking for what it looks like binaries right there. These binaries are getting fetched. There's a request happening in and go into the database. It's requesting the database keeping binaries. If it doesn't find the binaries, then it will return a 404, otherwise, it will just return an empty dictionary, which I am thinking it will get translated to JSON. An empty JSON object meaning hey, ESTs exists, but you see, it's empty. It doesn't return anything. That might be surprising because this is not when it would happen, say, for example, with a GET method. A HEAD is useful when you just want to poke. It's a slight poke that you're doing on the server and saying, hey, does these resources exist or doesn't it? With minimal effort on the client because the body doesn't return anything. You can see that's different from the GET request right here, which is the same thing. It requests the binaries, but once the response is ready, right here, it does some processing for returning a very complete body with lots of information right there. Those are some examples that I wanted to touch on. Lastly, we saw certain examples, especially here with Hugging Face deploy Azure, an application from Hugging Face. I'm going to actually go here and show you very quickly something that you should not do and you should try to do something a little bit better. We saw here that these are not documented. What happens when they're not documented? Well, someone would have to figure out, in this case, you want to interact with the predict. Well, you would have to understand that there's a slash generate, that's fine, but how does that body looked like? It seems it wants a text. Where's the text? You have to go to Line 10. It's a string. What's this string like? What examples should I look like? Those should be documented and you can see here, nothing is very documented. I actually created this as a demo, but I didn't take the time to document that. If you're running production code, if you're creating production applications, make sure that you're always documenting those endpoints and making sure that you provide examples. Those are some of the good practices that I think you should be putting together when you're building APIs."]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-09-14-30-04.png)"]},{"cell_type":"markdown","metadata":{},"source":["**FastAPI:** A Python web framework for building APIs."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from fastapi import FastAPI\n","\n","app = FastAPI()\n","\n","@app.get(\"/\")\n","def read_root():\n","    return {\"message\": \"Hello World\"}\n","\n","print(read_root())"]},{"cell_type":"markdown","metadata":{},"source":["**Flask:** A lightweight Python web framework."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from flask import Flask\n","\n","app = Flask(__name__)\n","\n","@app.route(\"/\")\n","def home():\n","    return \"Home Page\"\n","\n","if __name__ == \"__main__\":\n","    app.run()"]},{"cell_type":"markdown","metadata":{},"source":["**Transforms:** Hugging Face library for NLP tasks."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from transformers import pipeline\n","\n","classifier = pipeline(\"sentiment-analysis\")\n","result = classifier(\"I love this course\") \n","print(result)"]},{"cell_type":"markdown","metadata":{},"source":["**Onyx:** ML model server for high-performance inferencing."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["import onnxruntime as rt\n","\n","sess = rt.InferenceSession(\"model.onnx\")\n","input_name = sess.get_inputs()[0].name\n","res = sess.run(None, {input_name: x})"]},{"cell_type":"markdown","metadata":{},"source":["**OpenAPI:** Specification for API documentation."]},{"cell_type":"code","execution_count":null,"metadata":{},"outputs":[],"source":["from fastapi import FastAPI\n","from fastapi.openapi.utils import get_openapi\n","\n","app = FastAPI()\n","\n","def custom_openapi():\n","    return get_openapi(\n","        title=\"Custom title\",\n","        version=\"2.5.0\",\n","        description=\"Custom description\",\n","    )\n","    \n","app.openapi = custom_openapi"]},{"cell_type":"markdown","metadata":{},"source":["![](2024-02-06-03-06-28.png)"]}],"metadata":{"colab":{"authorship_tag":"ABX9TyNAnc3IBjNxONndNFHGocAe","collapsed_sections":[],"name":"M1Assignment1 Solution.ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.7.10"}},"nbformat":4,"nbformat_minor":0}
